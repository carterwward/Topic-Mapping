{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0752579dbebe7f4dfe7c1aa72eac13e23fc88be2cc1ea7ab14e1f8d69b2d97d12",
   "display_name": "Python 3.8.3 64-bit ('3.8')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pyLDAvis\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "\n",
    "# restore np.load for future normal usage\n",
    "# np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # x has shape [batch_size, n_classes]\n",
    "    e = np.exp(x)\n",
    "    n = np.sum(e, 1, keepdims=True)\n",
    "    return e/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dir = \"models/lyrics/\"\n",
    "n_topics = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/song_df.csv\")\n",
    "# \"integer -> word\" decoder \n",
    "decoder = np.load(path_to_dir+'decoder.npy')[()]\n",
    "\n",
    "vocab = list(decoder.values())\n",
    "\n",
    "# for restoring document ids, \"id used while training -> initial id\"\n",
    "doc_decoder = np.load(path_to_dir+'doc_decoder.npy')[()]\n",
    "docs = dataset.iloc[list(doc_decoder.values())][\"tokenized_lyrics\"].values\n",
    "\n",
    "doc_lengths = np.array([0 if pd.isna(tok) else len(tok.split()) for tok in docs])\n",
    "\n",
    "docs_compiled = list(itertools.chain.from_iterable([doc for doc in docs if not pd.isna(doc)]))\n",
    "term_frequency = np.array([docs_compiled.count(word) for word in vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(doc_decoder))\n",
    "print(len(doc_lengths))\n",
    "print(len(term_frequency))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('models/lyrics/lda2vec_models/60_epoch_model_state.pytorch', map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_weights = state['doc_weights.weight'].cpu().clone().numpy()\n",
    "topic_vectors = state['topics.topic_vectors'].cpu().clone().numpy()\n",
    "resulted_word_vectors = state['neg.embedding.weight'].cpu().clone().numpy()\n",
    "\n",
    "# distribution over the topics for each document\n",
    "topic_dist = softmax(doc_weights)\n",
    "\n",
    "# vector representation of the documents\n",
    "doc_vecs = np.matmul(topic_dist, topic_vectors)\n",
    "# rows are topics, cols are vocab, vals are probabilities\n",
    "topic_term_dist = softmax(np.matmul(topic_vectors, resulted_word_vectors.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_vecs.shape)\n",
    "print(topic_dist.shape)\n",
    "print(topic_vectors.shape)\n",
    "print(resulted_word_vectors.shape)\n",
    "print(doc_weights.shape)\n",
    "print(topic_term_dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard = pyLDAvis.prepare(topic_term_dist, topic_dist, doc_lengths, vocab, term_frequency)\n",
    "pyLDAvis.display(dashboard)\n",
    "pyLDAvis.save_html(dashboard, \"plots/lyrics_lda2vec.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = np.matmul(topic_vectors, resulted_word_vectors.T)\n",
    "most_similar = similarity.argsort(axis=1)[:, -10:]\n",
    "\n",
    "for j in range(n_topics):\n",
    "    topic_words = ' '.join([decoder[i] for i in reversed(most_similar[j])])\n",
    "    print('topic', j + 1, ':', topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}